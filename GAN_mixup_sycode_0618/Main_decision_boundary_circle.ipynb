{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main+decision_boundary_circle.ipynb",
      "provenance": [],
      "mount_file_id": "1UkMMou8OdPNpemSzNuTlnHd1eKdUyb8c",
      "authorship_tag": "ABX9TyPFdoPiA1WTEtcxV01WsRrB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soyeong792/ACTIVE_GAN/blob/master/GAN_mixup_sycode_0618/Main_decision_boundary_circle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjEZy9N1YAQo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "757e2c9a-6f52-4c87-8cfc-bf8652f87e78"
      },
      "source": [
        "cd drive/My\\ Drive/GAN_mixup_sycode_0618"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/GAN_mixup_sycode_0618\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCtEI9paQ1wo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython import display\n",
        "\n",
        "import torch\n",
        "import sys\n",
        "import pdb\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import copy\n",
        "import random\n",
        "import os\n",
        "import csv\n",
        "import itertools\n",
        "import functools\n",
        "import torch\n",
        "import argparse\n",
        "import errno\n",
        "import easydict\n",
        "#import foolbox as fb\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.nn import init\n",
        "from torch.nn import Parameter as P\n",
        "from torch.autograd.variable import Variable\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import TensorDataset, Dataset\n",
        "from torchvision.datasets import ImageFolder\n",
        "#import torchvision.utils as vutils\n",
        "from torchvision.utils import save_image\n",
        "#from torch.optim.lr_scheduler import StepLR, MultiStepLR\n",
        "from matplotlib import pyplot\n",
        "from pandas import DataFrame\n",
        "from numpy import genfromtxt\n",
        "\n",
        "from sklearn.datasets import make_circles, make_moons\n",
        "\n",
        "from utils_sy_0527_2 import *"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAKO-AdEXlUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#staretey_type에 따라서 query, train, update, predict 수행\n",
        "class Strategy:\n",
        "    def __init__(self,strategy_type,data_loader,idxs_lb,net,args):\n",
        "        self.strategy_type = strategy_type\n",
        "        self.n_epoch = args.active_num_epoch\n",
        "        self.num_workers  = data_loader.num_workers\n",
        "        self.batch_size = data_loader.batch_size\n",
        "        self.X = data_loader.dataset.tensors[0]\n",
        "        self.Y = data_loader.dataset.tensors[1]\n",
        "        self.idxs_lb = idxs_lb\n",
        "        self.net = net\n",
        "        self.n_pool = len(self.Y)\n",
        "        use_cuda = torch.cuda.is_available()\n",
        "        self.device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "        self.gan = args.gan\n",
        "        self.lr = args.lr\n",
        "        self.wd = args.wd\n",
        "        self.args = args\n",
        "\n",
        "\n",
        "    def query(self,n):\n",
        "        if self.strategy_type == 'RandomSampling':\n",
        "            #temp = np.random.choice(np.where(self.idxs_lb==0)[0], 2*n)\n",
        "            #temp = np.unique(temp)\n",
        "            #return temp[0:n]\n",
        "\n",
        "            temp = np.random.choice(np.where(self.idxs_lb==0)[0], n, replace = False) #replace 없이\n",
        "            return temp\n",
        "\n",
        "        elif self.strategy_type == 'GANgeneration':\n",
        "            temp = np.random.choice(np.where(self.idxs_lb==0)[0], 2*n)\n",
        "            temp = np.unique(temp)\n",
        "            return temp[0:n]\n",
        "        \n",
        "        elif self.strategy_type == 'GANdistance':\n",
        "            idxs_unlabeled = np.arange(self.n_pool)[~self.idxs_lb]\n",
        "            unlabelX = self.X[idxs_unlabeled]\n",
        "            unlabelY = self.Y[idxs_unlabeled]\n",
        "            data_ = self.X\n",
        "            label_= self.Y\n",
        "            query_metric = np.empty((1,len(self.X)))\n",
        "            newY = np.empty((1,len(self.X)))\n",
        "            for i in range(len(unlabelY)):\n",
        "                _,_,dis1 = get_proj_distance_square(unlabelX[i], 0, data_,label_,self.args)\n",
        "                _,_,dis2 = get_proj_distance_square(unlabelX[i], 1, data_,label_,self.args)\n",
        "\n",
        "                print('distance calculating, with unlabeled set {} / {}'.format(i+1,len(unlabelY)))\n",
        "                query_metric[0,i] = np.absolute(dis1.detach().cpu()-dis2.detach().cpu())\n",
        "                newY[0,i] = 0 if dis1<dis2 else 1\n",
        "\n",
        "            query_index = np.unique(np.ceil((np.argsort(query_metric)-1)/2))\n",
        "            query_index = query_index.astype(int)\n",
        "            #unlabelY[query_index[0:n]]=newY[query_index[0:n]]\n",
        "            self.Y[idxs_unlabeled[query_index[0:n]]] = torch.LongTensor(newY[0,query_index[0:n]])\n",
        "\n",
        "            return idxs_unlabeled[query_index[0:n]]\n",
        "\n",
        "    def update(self, idxs_lb):\n",
        "        self.idxs_lb = idxs_lb\n",
        "\n",
        "    def _train(self, loader_tr, optimizer):\n",
        "        self.clf.train()\n",
        "        criterion = self.args.criterion\n",
        "        for batch_idx, (x, y, idxs) in enumerate(loader_tr):\n",
        "            x = x.to(self.device)\n",
        "            y = y.to(self.device)\n",
        "            optimizer.zero_grad()\n",
        "            out = self.clf.forward(x.cuda().float())  \n",
        "            loss = criterion(out, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    def train(self):\n",
        "        self.clf = self.net.to(self.device)\n",
        "        optimizer = optim.Adam(self.clf.parameters(), lr=self.lr, weight_decay=self.wd)\n",
        "        idxs_train = np.arange(self.n_pool)[self.idxs_lb]\n",
        "        loader_tr = torch.utils.data.DataLoader(TensorDataset(self.X[idxs_train], self.Y[idxs_train],torch.Tensor(idxs_train)), batch_size=self.batch_size,\n",
        "                            shuffle=True, num_workers=self.num_workers)\n",
        "\n",
        "        for epoch in range(1, self.n_epoch+1):\n",
        "            self._train(loader_tr, optimizer)\n",
        "\n",
        "        self.net = self.clf\n",
        "        #return self.clf\n",
        "\n",
        "\n",
        "    #predict해서 accuracy를 출력 \n",
        "    def predict(self,test_loader):\n",
        "\n",
        "        \n",
        "        self.clf=self.net\n",
        "        self.clf.eval()\n",
        "        # = torch.zeros(len(test_loader), dtype=Y.dtype)\n",
        "        acc = 0\n",
        "        total = 0\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (x,y) in enumerate(test_loader):\n",
        "                x, y = x.to(self.device), y.to(self.device)\n",
        "                output = self.clf.forward(x.cuda().float())\n",
        "                _, pred = torch.max(output,1)\n",
        "                total += y.size(0)\n",
        "                correct += (pred==y).sum().item()\n",
        "            acc = correct / total\n",
        "        return acc\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRqspNuyQvZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#classifier Net\n",
        "class simple_Ndim_Net(torch.nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(simple_Ndim_Net, self).__init__()\n",
        "        \n",
        "        self.num_layer = args.num_layer\n",
        "        self.data_dim = args.data_dim\n",
        "        self.num_class = args.num_class\n",
        "        \n",
        "        self.fc1 = torch.nn.Linear(self.data_dim, 64)\n",
        "        self.fc2 = torch.nn.Linear(64, 128)\n",
        "        if self.num_layer >= 4:\n",
        "            self.fc3 = torch.nn.Linear(128, 128)\n",
        "            self.fc4 = torch.nn.Linear(128, 128)\n",
        "        if self.num_layer == 6:\n",
        "            self.fc5 = torch.nn.Linear(128, 128)\n",
        "            self.fc6 = torch.nn.Linear(128, 128)        \n",
        "        self.fc7 = torch.nn.Linear(128, self.num_class)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.relu(self.fc4(x))\n",
        "        if self.num_layer == 6:\n",
        "            x = F.relu(self.fc5(x))\n",
        "            x = F.relu(self.fc6(x))\n",
        "        x = self.fc7(x)\n",
        "\n",
        "        return x\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhxchnHDtys7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######SHOW DECISION BOUNDARY###############\n",
        "def show_synthetic(model, X_test, data_, label_, data_type, train_type, epoch, total_data_=0, n_samples=0, num_augment=0):\n",
        "    sm = torch.nn.Softmax(dim=1)\n",
        "    model.eval() #test\n",
        "\n",
        "    #X_test = (x_max - x_min) * torch.rand(num_test,data_dim) + x_min\n",
        "    pred_test = model(X_test).detach()\n",
        "    pred_test = sm(pred_test)\n",
        "\n",
        "    #decision boundary\n",
        "    plt.scatter(X_test[:,0].cpu(), X_test[:,1].cpu(), c=(pred_test[:,1].cpu()>=0.5))\n",
        "    #train_data 분포\n",
        "    plt.scatter(data_[:,0], data_[:,1], c=label_, edgecolor=['w' if i==0 else 'k' for i in label_])\n",
        "\n",
        "    #옆에 bar 표시. 0은 보라색, 1은 노란색.\n",
        "    plt.colorbar()\n",
        "\n",
        "    plt.axis('equal')\n",
        "    plt.show()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XsX0NOTQpwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###########################\n",
        "##### active_learning #####\n",
        "###########################\n",
        "\n",
        "#supervised learning train\n",
        "def train_fullysup(train_loader,test_loader,model,args):\n",
        "    device= args.device\n",
        "    #model = simple_Ndim_Net(args)    \n",
        "    #print(model)\n",
        "    criterion = args.criterion.to(device) #nn.MSELoss() # nn.CrossEntropyLoss() #\n",
        "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.wd) \n",
        "    total_train_loss,total_train_acc,total_test_loss,total_test_acc=[],[],[],[]\n",
        "    model = model.to(device)\n",
        "    for epoch in range(args.epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "        #print(list(model.parameters()))\n",
        "                \n",
        "        for batch_idx, (data,labels) in enumerate(train_loader):\n",
        "            data,labels = data.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data.float())\n",
        "            \n",
        "            loss = criterion(output, labels) #torch.eye(2)[labels].cuda())     \n",
        "            #print(output,labels,loss)   \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            #print(model.parameters())\n",
        "            total_loss += loss.item()\n",
        "            _, val_pred = torch.max(model.forward(data.float()),1)\n",
        "            total_acc += torch.sum(val_pred==labels.long()).sum().item()/len(labels)\n",
        "\n",
        "            \n",
        "        #한 epoch 마다 출력\n",
        "        show_synthetic(model, X_test, data_, label_, data_type, train_type, epoch)\n",
        "\n",
        "        total_train_loss.append(total_loss/len(train_loader))\n",
        "        total_train_acc.append(total_acc/len(train_loader))\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            total_loss = 0\n",
        "            total_acc = 0\n",
        "            for batch_idx, (data,labels) in enumerate(test_loader):\n",
        "                data,labels = data.to(device), labels.to(device)\n",
        "                output = model.forward(data.float())\n",
        "                loss = criterion(output, labels) # torch.eye(2)[labels].cuda()) # labels)        \n",
        "                total_loss += loss.item()\n",
        "                _, val_pred = torch.max(model.forward(data.float()),1)\n",
        "                total_acc += torch.sum(val_pred==labels.long()).sum().item()/len(labels)\n",
        "\n",
        "            \n",
        "            total_test_loss.append(total_loss/len(test_loader))\n",
        "            total_test_acc.append(total_acc/len(test_loader))\n",
        "\n",
        "        #print(total_train_loss[-1],total_train_acc[-1],total_test_loss[-1],total_test_acc[-1])\n",
        "\n",
        "    return total_train_acc[-1],total_test_acc[-1]#total_train_loss,total_train_acc,total_test_loss,total_test_acc\n",
        "\n",
        "\n",
        "#active learningb train\n",
        "def train_active(train_loader,test_loader,net,strategy_type,args):\n",
        "    NUM_ROUND = args.NUM_ROUND\n",
        "    NUM_INIT_LABEL = args.NUM_INIT_LABEL\n",
        "    NUM_QUERY = args.NUM_QUERY\n",
        "    active_num_epoch = args.active_num_epoch #3\n",
        "    acc = torch.zeros((1,NUM_ROUND+1))\n",
        "\n",
        "    n_pool = len(train_loader.dataset.tensors[1])\n",
        "    idxs_lb = np.zeros(n_pool,dtype=bool)\n",
        "    idxs_temp = np.arange(n_pool)\n",
        "    np.random.shuffle(idxs_temp)\n",
        "    idxs_lb[idxs_temp[:NUM_INIT_LABEL]] = True\n",
        "\n",
        "    #X_te = active_test_loader.dataset.tensors[0]\n",
        "    #Y_te = active_test_loader.dataset.tensors[1]\n",
        "\n",
        "    strategy = Strategy(strategy_type,train_loader,idxs_lb,net,args)\n",
        "\n",
        "    for active_epoch in range(active_num_epoch):\n",
        "      strategy.train()\n",
        "      acc[0,0] = strategy.predict(test_loader)\n",
        "      #print('ROUND 0')\n",
        "      print('ROUND 0 Labeled size {} acitve_epoch {} testing accuracy {}'.format(sum(idxs_lb==1), active_epoch, acc[0,0]))\n",
        "\n",
        "    for rd in range(1,NUM_ROUND+1):\n",
        "        #print('ROUND {}'.format(rd))\n",
        "        \n",
        "        for active_epoch in range(active_num_epoch):\n",
        "          if active_epoch == 0 :\n",
        "            # query\n",
        "            q_idx = strategy.query(NUM_QUERY)\n",
        "            idxs_lb[q_idx] = True\n",
        "            print(f'query 된 점들 : {q_idx}')\n",
        "\n",
        "            # update\n",
        "            strategy.update(idxs_lb)\n",
        "            strategy.train()\n",
        "\n",
        "            # round accuracy\n",
        "            acc[0,rd] = strategy.predict(test_loader)\n",
        "            #print('ROUND {} Labeled size {} testing accuracy {}'.format(rd, sum(idxs_lb==1), acc[0,rd]))\n",
        "            print('ROUND {} Labeled size {} acitve_epoch {} testing accuracy {}'.format(rd, sum(idxs_lb==1), active_epoch, acc[0,rd]))\n",
        "          \n",
        "          else :\n",
        "            strategy.train()\n",
        "            # round accuracy\n",
        "            acc[0,rd] = strategy.predict(test_loader)\n",
        "            #print('ROUND {} Labeled size {} testing accuracy {}'.format(rd, sum(idxs_lb==1), acc[0,rd]))\n",
        "            print('ROUND {} Labeled size {} acitve_epoch {} testing accuracy {}'.format(rd, sum(idxs_lb==1), active_epoch, acc[0,rd]))\n",
        "          \n",
        "          show_synthetic(net, X_test, data_, label_, data_type, train_type, rd)\n",
        "\n",
        "\n",
        "    return acc\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-BrkS1pbV8Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############## CONSTANTS #######################\n",
        "\n",
        "args = easydict.EasyDict({'data_type': 'circle',\n",
        "        'distance_type': 'L2',\n",
        "        'train_add_noise' : False,\n",
        "        'network_name' : None,\n",
        "        'lr' : 5e-3,\n",
        "        'wd' : 1e-4,\n",
        "        'epochs' : 20,\n",
        "        'batch_size' : 4,\n",
        "        'label_GAN' : 2,\n",
        "        'n_workers' : 1,\n",
        "        'device' : 'cuda',\n",
        "        'label_first' : 0,\n",
        "        'label_last' : 1,\n",
        "        'image_size_ref' : 32,\n",
        "        'num_class' :2 ,\n",
        "        'num_class_total' : 2,\n",
        "        'data_class' : 'Synthetic',\n",
        "        'num_layer' : 6,\n",
        "        'z_dim' : 1,\n",
        "        'data_dim' : 2,\n",
        "        'num_epochs_z' : 10 ,\n",
        "        'num_random_z' : 3,\n",
        "        'NUM_INIT_LABEL' : 4,\n",
        "        'NUM_QUERY' : 4,\n",
        "        'NUM_ROUND' : 24,\n",
        "        'NUM_ITER': 20,\n",
        "        'active_num_epoch' : 5,\n",
        "        'criterion' : nn.CrossEntropyLoss(),\n",
        "        'n_samples_train' : 100,\n",
        "        'n_samples_test' : 1000,\n",
        "        'gan' : None,\n",
        "        'show_image' : True\n",
        "        })\n",
        "\n",
        "#args = args_pool[DATA_NAME]\n",
        "\n",
        "NUM_ROUND = int((args['n_samples_train']-args['NUM_INIT_LABEL'])/args['NUM_QUERY'])\n",
        "#n_samples_train = 100\n",
        "#n_samples_test = 1000\n",
        "\n",
        "\n",
        "data_type = args.data_type\n",
        "distance_type = args['distance_type']\n",
        "train_add_noise = args['train_add_noise']\n",
        "lr = args['lr'] \n",
        "wd = args['wd'] \n",
        "network_name = args['network_name']\n",
        "epochs = args['epochs']\n",
        "batch_size = args['batch_size'] \n",
        "\n",
        "label_GAN = args['label_GAN']\n",
        "n_workers = args['n_workers']\n",
        "device = args['device']\n",
        "label_first = args['label_first']\n",
        "label_last = args['label_last']\n",
        "image_size_ref = args['image_size_ref']\n",
        "num_class = args['num_class']\n",
        "num_class_total = args['num_class_total']\n",
        "data_class = args['data_class']\n",
        "\n",
        "num_layer = args['num_layer']\n",
        "z_dim = args['z_dim']\n",
        "data_dim = args['data_dim']\n",
        "num_epochs_z = args['num_epochs_z']\n",
        "num_random_z = args['num_random_z']\n",
        "NUM_INIT_LABEL = args['NUM_INIT_LABEL']\n",
        "NUM_QUERY = args['NUM_QUERY']\n",
        "NUM_ROUND = args['NUM_ROUND']\n",
        "NUM_ITER = args['NUM_ITER']\n",
        "active_num_epoch = args['active_num_epoch']\n",
        "criterion = args['criterion']\n",
        "n_samples_train = args['n_samples_train']\n",
        "n_samples_test = args['n_samples_test']\n",
        "\n",
        "train_type = 'vanilla_training'\n",
        "\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "if torch.cuda.device_count() > 2:\n",
        "    args['device'] = 'cuda:3' if use_cuda else 'cpu' \n",
        "else:\n",
        "    args['device'] = 'cuda' if use_cuda else 'cpu'\n",
        "\n",
        "if use_cuda:    args['n_workers'] = 4\n",
        "else:    args['n_workers'] = 1\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeJSWS8BbV7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######## LOAD DATASET\n",
        "###### LOAD Train data ########\n",
        "\n",
        "data_, label_, test_data_, test_label_, X_test = \\\n",
        "load_synthetic_data(args['data_type'], args['data_dim'], args['n_samples_train'], args['n_samples_test'], args.show_image, args['device'], args['train_add_noise']) \n",
        "    \n",
        "saved_generator = load_GAN(data_type, data_dim, z_dim, num_class, device, train_add_noise, label_GAN) \n",
        "saved_generator.eval()\n",
        "saved_generator = saved_generator.to(device)   \n",
        "#print(saved_generator)\n",
        "\n",
        "args['gan'] = saved_generator\n",
        "\n",
        "tr_dataset = TensorDataset(data_, label_)\n",
        "te_dataset = TensorDataset(test_data_, test_label_)\n",
        "active_train_loader = torch.utils.data.DataLoader(tr_dataset, batch_size = batch_size, shuffle=True, num_workers = n_workers)    \n",
        "active_test_loader = torch.utils.data.DataLoader(te_dataset, batch_size = batch_size, shuffle=True, num_workers = n_workers)    \n",
        "\n",
        "############# start active training\n",
        "#trial_num = int(np.random.randint(10))\n",
        "#seed((int)(42+trial_num))\n",
        "\n",
        "#seed = 1\n",
        "seed(1)\n",
        "\n",
        "#acc = torch.zeros((2)) #NUM_ITER))#,NUM_ROUND+1))\n",
        "fin_acc_rand = torch.zeros((NUM_ROUND+1)) #NUM_ITER,\n",
        "fin_acc_GAN = torch.zeros((NUM_ROUND+1))#NUM_ITER,\n",
        "\n",
        "#Fully supervised learning.\n",
        "#arg.epoch = 20만큼 돌림.\n",
        "network = simple_Ndim_Net(args)\n",
        "acc_sup_train,acc_sup_test = train_fullysup(active_train_loader,active_test_loader,network,args)\n",
        "#acc[0]=((num_iter*acc[0])+acc_sup_train)/(num_iter+1)\n",
        "#acc[1]=((num_iter*acc[1])+acc_sup_test)/(num_iter+1)\n",
        "print(f'fullysup train acc : {acc_sup_train}, fullysup test acc : {acc_sup_test}')\n",
        "\n",
        "\n",
        "acc_avg = torch.zeros(NUM_ROUND + 1)\n",
        "\n",
        "#Active Learning\n",
        "#NUM_ITER = active learning epoch 수\n",
        "for num_iter in range(NUM_ITER):\n",
        "\n",
        "    print(f'NUM_ITER : {num_iter}')\n",
        "    #RandomSampling accuracy\n",
        "    network = simple_Ndim_Net(args)\n",
        "    strategy_type = 'RandomSampling'\n",
        "    acc_rand = train_active(active_train_loader,active_test_loader,network,strategy_type,args)\n",
        "    #train_with_randomquery(tr_dataset,active_test_loader,network,criterion,active_batch_size,n_workers,NUM_ROUND,NUM_INIT_LABEL,NUM_QUERY)\n",
        "    #acc2 = train_with_GANmixupmove(tr_dataset,network,optimizer,criterion,active_batch_size,n_workers)\n",
        "    \n",
        "    acc_avg = (num_iter*acc_avg + acc_rand[0])/(num_iter+1);\n",
        "    print(acc_avg)\n",
        "\n",
        "\n",
        "    #GANdistance accuracy\n",
        "    #우선 이거 생각하지 말 것\n",
        "    '''\n",
        "    network = simple_Ndim_Net(args)\n",
        "    strategy_type = 'GANdistance'\n",
        "    acc_GAN = train_active(active_train_loader,active_test_loader,network,strategy_type,args)\n",
        "\n",
        "    fin_acc_rand = ((num_iter*fin_acc_rand)+torch.FloatTensor(acc_rand))/(num_iter+1)\n",
        "    fin_acc_GAN = ((num_iter*fin_acc_rand)+torch.FloatTensor(acc_GAN))/(num_iter+1)\n",
        "\n",
        "    print('single iteration finished')\n",
        "    print(num_iter,'\\n',acc,'\\n',fin_acc_rand,'\\n',fin_acc_GAN)\n",
        "    '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rtr5zxRZlne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.arange(NUM_ROUND+1)\n",
        "plt.plot(x,acc_avg)\n",
        "\n",
        "print(acc_avg)\n",
        "plt.title(f'Rand last acc : {acc_avg[-1]}')\n",
        "#plt.savefig('savefig/Rand_Sampling_epoch_20.png',dpi = 300)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}